---
title: Feature Description
---

1.  ğŸ¨ Brand new UI interface (some interfaces are still pending updates)
2.  ğŸŒ Multi-language support (to be improved)
3.  ğŸ¨ Added [Midjourney-Proxy(Plus)](https://github.com/novicezk/midjourney-proxy) API support
4.  ğŸ’° Supports online top-up functionality, configurable in System Settings:
    *   - [x] Epay
5.  ğŸ” Supports querying usage Quota by key:
    *   In conjunction with the project [neko-api-key-tool](https://github.com/Calcium-Ion/neko-api-key-tool), querying usage by key can be achieved.
6.  ğŸ“‘ Pagination supports selecting the number of items displayed per page
7.  ğŸ”„ Compatible with the original One API database, the original database (one-api.db) can be used directly
8.  ğŸ’µ Supports model billing by usage count, configurable in System Settings - Operation Settings
9.  âš–ï¸ Supports **weighted random** Channel selection
10. ğŸ“ˆ Data Dashboard (Console)
11. ğŸ”’ Configurable models that a Token can call
12. ğŸ¤– Supports Telegram authorized login:
    1.  System Settings - Configure Login & Registration - Allow login via Telegram
    2.  Enter command /setdomain to [@Botfather](https://t.me/botfather)
    3.  Select your bot, then enter http(s)://your_website_address/login
    4.  The Telegram Bot Name is the bot username string without the @
13. ğŸµ Added [Suno API](https://github.com/Suno-API/Suno-API) API support
14. ğŸ”„ Supports Rerank models, currently compatible with Cohere and Jina, and can be integrated with Dify
15. âš¡ **[OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime/integration)** - Supports OpenAI's Realtime API, supports Azure Channel
16. Supports using the route /chat2link to enter the chat interface
17. ğŸ§  Supports setting reasoning effort via model name suffix:
    1.  OpenAI o-series models
        *   - Add suffix `-high` to set as high reasoning effort (e.g.: `o3-mini-high`)
        *   - Add suffix `-medium` to set as medium reasoning effort (e.g.: `o3-mini-medium`)
        *   - Add suffix `-low` to set as low reasoning effort (e.g.: `o3-mini-low`)
    2.  Claude thinking models
        *   - Add suffix `-thinking` to enable thinking mode (e.g.: `claude-3-7-sonnet-20250219-thinking`)
18. ğŸ”„ Thinking to Content, supports setting the `thinking_to_content` option in `Channel - Edit - Channel Extra Settings`, default `false`. When enabled, it will convert the thinking content `reasoning_content` into a `<think>` tag and append it to the returned content.
19. ğŸ”„ Model Rate Limiting, supports setting model rate limits in `System Settings - Rate Limit Settings`, including total request count limit and successful request count limit.
20. ğŸ’° Cache Billing Support, when enabled, billing can occur at a set Ratio upon cache hit:
    1.  Set the Prompt Cache Ratio option in `System Settings - Operation Settings`
    2.  Set the Prompt Cache Ratio in the Channel, range 0-1. For example, setting it to 0.5 means billing at 50% upon cache hit.
    3.  Supported Channels:
        *   - [x] OpenAI
        *   - [x] Azure
        *   - [x] DeepSeek
        *   - [ ] Claude